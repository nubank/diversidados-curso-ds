{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from utils import DecisionTree\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0,50)\n",
    "x = pd.DataFrame({'x':x})\n",
    "\n",
    "y1 = np.random.uniform(10,15,10)\n",
    "y2 = np.random.uniform(20,25,10)\n",
    "y3 = np.random.uniform(0,5,10)\n",
    "y4 = np.random.uniform(30,32,10)\n",
    "y5 = np.random.uniform(13,17,10)\n",
    "\n",
    "y = np.concatenate((y1,y2,y3,y4,y5))\n",
    "y = y[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(x,y, 'o')\n",
    "plt.title(\"x vs. y\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizagem Fraca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nossa árvore de decisão encontra o melhor jeito de dividir o dataset em dois grupos, usando o método `find_better_split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predf = 0\n",
    "\n",
    "tree = DecisionTree(x,y)\n",
    "tree.find_better_split(0)\n",
    "r = np.where(x == tree.split)[0][0]\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(sharey=True, figsize = (13,5))\n",
    "ax.plot(x, y, 'o')\n",
    "ax.set_title(f'Divisão da Árvore de Decisão')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.axvline(r, c=\"k\", ls=\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada um dos dois grupos o nosso _weak learner_ prevê encontra a média dos elementos. O processo pode ser repetido, a partir dos residuos desse modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(y)\n",
    "\n",
    "left_idx = np.where(x <= tree.split)[0]\n",
    "right_idx = np.where(x > tree.split)[0]\n",
    "\n",
    "predi = np.zeros(n)\n",
    "np.put(predi, left_idx, np.repeat(np.mean(y[left_idx]), r))\n",
    "np.put(predi, right_idx, np.repeat(np.mean(y[right_idx]), n-r))\n",
    "\n",
    "predi = predi[:,None]\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize = (20,5))\n",
    "ax1.plot(x, y, 'o')\n",
    "ax1.plot(x, predi, c=\"k\", ls=\"--\")\n",
    "ax1.set_title(f'Weak Learner')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.axvline(r, c=\"k\", ls=\"--\")\n",
    "\n",
    "\n",
    "tree = DecisionTree(x,y - predi)\n",
    "tree.find_better_split(0)\n",
    "r = np.where(x == tree.split)[0][0]\n",
    "\n",
    "ax2.plot(x, y - predi, 'o')\n",
    "ax2.set_title(f'Residuos (repete-se o processo)')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('Residuo')\n",
    "ax2.axvline(r, c=\"k\", ls=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = x\n",
    "yi = y\n",
    "ei = 0\n",
    "n = len(yi)\n",
    "predf = 0\n",
    "\n",
    "for i in range(30):\n",
    "    tree = DecisionTree(xi,yi)\n",
    "    tree.find_better_split(0)\n",
    "    \n",
    "    r = np.where(xi == tree.split)[0][0]    \n",
    "    \n",
    "    left_idx = np.where(xi <= tree.split)[0]\n",
    "    right_idx = np.where(xi > tree.split)[0]\n",
    "    \n",
    "    predi = np.zeros(n)\n",
    "    np.put(predi, left_idx, np.repeat(np.mean(yi[left_idx]), r))\n",
    "    np.put(predi, right_idx, np.repeat(np.mean(yi[right_idx]), n-r))\n",
    "    \n",
    "    predi = predi[:,None]\n",
    "    predf = predf + predi\n",
    "    \n",
    "    ei = y - predf\n",
    "    yi = ei\n",
    "    \n",
    "    \n",
    "    xa = np.array(x.x) \n",
    "    order = np.argsort(xa)\n",
    "    xs = np.array(xa)[order]\n",
    "    ys = np.array(predf)[order]\n",
    "\n",
    "    f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True, figsize = (18,3.5))\n",
    "\n",
    "    ax1.plot(x, y - (predf - predi), 'go')\n",
    "    ax1.plot(x, predi, 'g', ls=\"--\")\n",
    "    ax1.set_title(f'Weak Learner (Iteração {i+1})')\n",
    "    ax1.set_xlabel('x')\n",
    "    ax1.set_ylabel('yi')\n",
    "    ax1.axvline(r, c=\"k\", ls=\"--\")\n",
    "    \n",
    "    ax2.plot(x,y, 'o')\n",
    "    ax2.plot(xs, ys, 'r')\n",
    "    ax2.set_title(f'Previsão Final (Iteração {i+1})')\n",
    "    ax2.set_xlabel('x')\n",
    "    ax2.set_ylabel('y')\n",
    "\n",
    "    ax3.plot(x, ei, 'go')\n",
    "    ax3.set_title(f'Residuos (Iteração {i+1})')\n",
    "    ax3.set_xlabel('x')\n",
    "    ax3.set_ylabel('Residuals')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Boston\n",
    "\n",
    "Dataset com preços de imóveis em Boston\n",
    "\n",
    "\n",
    "#### Atributos\n",
    "- **CRIM** - Crime per capita\n",
    "- **ZN** - Proporção de área residencial\n",
    "- **INDUS** - Proporção de área industrial\n",
    "- **CHAS** - Charles River dummy variable\n",
    "- **NOX** -  Concentração de óxido nítrico (partes por 10 milhões)\n",
    "- **RM** - Média de cômodos por habitação\n",
    "- **AGE** - Proporção de casas/prédios construídos antes de 1940\n",
    "- **DIS** - Distância (ponderada) para centros de emprego\n",
    "- **RAD** - Índice de acessibilidade a vias centrais\n",
    "- **TAX** - Taxa de imposto\n",
    "- **PTRATIO** - Proporção número de professores/número de estudantes\n",
    "- **B** - 1000(Bk — 0.63)², onde Bk é a proporção de negros\n",
    "- **LSTAT** - Status da população\n",
    "\n",
    "#### Target\n",
    "- **MEDV** - Mediana do valor dos imóveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "X = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "y = pd.Series(boston.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    reg_lambda=1,\n",
    "    gamma=0,\n",
    "    reg_alpha=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(regressor.feature_importances_.reshape(1, -1), columns=boston.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"EQM (Treino): {mean_squared_error(y_train, regressor.predict(X_train))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"EQM (Teste): {mean_squared_error(y_test, regressor.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    reg_lambda=1,\n",
    "    gamma=0,\n",
    "    reg_alpha=0,\n",
    "    max_depth=5,\n",
    "    min_child_weight=1,\n",
    "    random_state=42\n",
    ")\n",
    "regressor.fit(X_train, y_train)\n",
    "print(f\"MSE (Treino): {mean_squared_error(y_train, regressor.predict(X_train))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE (Teste): {mean_squared_error(y_test, regressor.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min Child Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    reg_lambda=1,\n",
    "    gamma=0,\n",
    "    reg_alpha=0,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    "    min_child_weight=7\n",
    ")\n",
    "regressor.fit(X_train, y_train)\n",
    "print(f\"MSE (Treino): {mean_squared_error(y_train, regressor.predict(X_train))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE (Teste): {mean_squared_error(y_test, regressor.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reg_Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    reg_lambda=1,\n",
    "    gamma=0,\n",
    "    reg_alpha=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    "    min_child_weight=7\n",
    ")\n",
    "regressor.fit(X_train, y_train)\n",
    "print(f\"MSE (Treino): {mean_squared_error(y_train, regressor.predict(X_train))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE (Teste): {mean_squared_error(y_test, regressor.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    reg_lambda=1,\n",
    "    gamma=0,\n",
    "    reg_alpha=0.001,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    "    min_child_weight=7\n",
    ")\n",
    "regressor.fit(X_train, y_train)\n",
    "print(f\"MSE (Treino): {mean_squared_error(y_train, regressor.predict(X_train))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE (Teste): {mean_squared_error(y_test, regressor.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados de diabetes\n",
    "Dados de 442 pacientes de diabetes (idade, sexo, medidas de serum, ...), alem de uma variável-resposta de progressao da doença um ano depois\n",
    "\n",
    "#### Atributos\n",
    "- **Idade**\n",
    "- **Sexo**\n",
    "- **IMC**\n",
    "- **Pressão Sanguinea**\n",
    "- **S1**\n",
    "- **S2**\n",
    "- **S3**\n",
    "- **S4**\n",
    "- **S5**\n",
    "- **S6**\n",
    "\n",
    "\n",
    "#### Target\n",
    "Medida quantitativa de progressão da doença"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = load_diabetes()\n",
    "\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classificação\n",
    "Como sugestão, deixamos um problema de **classificação** que pode ser resolvidos usando a classe _xgboost.XGBClassifier_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
